{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section III c -Decision Tree Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree Regression uses non linear methods to classify the dataset. The Decision tree builds regression model by breaking down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. Decisions trees takes each feature and makes a decision / split on a value that provides the most information gain(minimum entropy). Then it alternates to another feature and makes the same split decision. It continues to do so until no further information gain is available. The overall structure of a decision tree includes a decision node and a leaf node. The decision has two or more branches that each represent the value of the feature tested while the leaf node represents the decision target. Decision trees can handle both numerical and categorical data.\n",
    "\n",
    "\n",
    "\n",
    "![](./images/15.jpg \"\")\n",
    "![](./images/16.jpg \"\")\n",
    "\n",
    "When classifying a new data point, take the average values of all the data points in that decision section.\n",
    "\n",
    "Pros: There's no need for feature scaling so results can be interpretable and works on non linear data. \n",
    "\n",
    "Cons: Does not work well if dataset is too small and overfitting can easilty occur\n",
    "\n",
    "* **Principal Component Analysis** — Before feeding into the Decision Tree, we will do a PCA; varying the number of components from N=10 to N=50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression with PCA (n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np   #Mathematics library\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import pandas as pd  #manage datasets\n",
    "import seaborn as sea\n",
    "\n",
    "\n",
    "df = pd.read_csv('FinishMissing.csv')\n",
    "df=df.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop outliers before splitting ex and y\n",
    "avg = df['logerror'].mean()\n",
    "std = df['logerror'].std()\n",
    "upper_outlier = avg + 2*std\n",
    "lower_outlier = avg - 2*std\n",
    "#round up to drop outliers, til reasonable\n",
    "df=df[ df.logerror > -0.32 ]\n",
    "df=df[ df.logerror < 0.34 ]\n",
    "df.to_csv('OutlierRemoved.csv')  #big file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############Create Dummy variables for Categorical data\n",
    "df=pd.get_dummies(df,columns=['taxdelinquencyflag','fireplaceflag','propertyzoningdesc','propertycountylandusecode','hashottuborspa','airconditioningtypeid','architecturalstyletypeid','buildingqualitytypeid','buildingclasstypeid','decktypeid','fips','heatingorsystemtypeid','pooltypeid10','pooltypeid2','pooltypeid7','propertylandusetypeid','regionidcounty','regionidcity','regionidzip','regionidneighborhood','storytypeid','typeconstructiontypeid','month','day'],drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=df\n",
    "\n",
    "#split into response and features, skip to next for testing\n",
    "X = dataset.iloc[:, 2:].values\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying PCA * requires feature scaling\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 10) # number of principal components explain variance, use '0' first\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X = np.concatenate((X_train,X_test),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting a new result\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0123499774861\n",
      "0.11113045256\n"
     ]
    }
   ],
   "source": [
    "# Mean Square Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ceribrum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0125399244758\n",
      "0.111981804218\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with all three features\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(regressor, X, y, cv=4, scoring='neg_mean_squared_error')\n",
    "mse_scores = -scores\n",
    "# calculate the average MSE\n",
    "print(mse_scores.mean())\n",
    "rmse_kfold = np.sqrt(mse_scores.mean())\n",
    "print(rmse_kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression with PCA (n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=df\n",
    "\n",
    "#split into response and features, skip to next for testing\n",
    "X = dataset.iloc[:, 2:].values\n",
    "y = dataset.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################### Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################### Feature Scaling required for Neural Network & Feature Extraction\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### DIMENSIONALITY REDUCTION : PRINCIPAL COMPONENT ANALYSIS(PCA)\n",
    "# Applying PCA * requires feature scaling\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 20) # number of principal components explain variance, use '0' first\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X = np.concatenate((X_train,X_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting a new result\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0125167714828\n",
      "0.111878378084\n"
     ]
    }
   ],
   "source": [
    "# Mean Square Error\n",
    "mse = mean_squared_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0129311123273\n",
      "0.113715048816\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with all three features\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(regressor, X, y, cv=4, scoring='neg_mean_squared_error')\n",
    "mse_scores = -scores\n",
    "# calculate the average MSE\n",
    "print(mse_scores.mean())\n",
    "rmse_kfold = np.sqrt(mse_scores.mean())\n",
    "print(rmse_kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression with PCA (n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################PCA N=50\n",
    "dataset=df\n",
    "\n",
    "#split into response and features, skip to next for testing\n",
    "X = dataset.iloc[:, 2:].values\n",
    "y = dataset.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################### Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################### Feature Scaling required for Neural Network & Feature Extraction\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### DIMENSIONALITY REDUCTION : PRINCIPAL COMPONENT ANALYSIS(PCA)\n",
    "# Applying PCA * requires feature scaling\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 50) # number of principal components explain variance, use '0' first\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X = np.concatenate((X_train,X_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting a new result\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0127332906904\n",
      "0.112841883582\n"
     ]
    }
   ],
   "source": [
    "# Mean Square Error\n",
    "mse = mean_squared_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0130116648027\n",
      "0.114068684584\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with all three features\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(regressor, X, y, cv=4, scoring='neg_mean_squared_error')\n",
    "mse_scores = -scores\n",
    "# calculate the average MSE\n",
    "print(mse_scores.mean())\n",
    "rmse_kfold = np.sqrt(mse_scores.mean())\n",
    "print(rmse_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
